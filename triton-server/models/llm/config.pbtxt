name: "llm"
platform: "ensemble"
max_batch_size : 8


#input to the model 
input [
    {
        name: "TEXT"
        data_type: TYPE_STRING
        dims: [ -1 ] 
        # -1 means dynamic axis, aka this dimension may change 
    }
]

#output of the model
output [
    {
        name: "START_LOGITS"
        data_type: TYPE_FP32
        dims: [ -1 ] 
    },
    {
        name: "END_LOGITS"
        data_type: TYPE_FP32
        dims: [ -1 ] 
    }
]

#Type of scheduler to be used
ensemble_scheduling {
    step [
        {
            model_name: "tokenizer"
            model_version: -1
            input_map {
            key: "text"
            value: "TEXT"
        }
        output_map [
        {
            key: "input_ids"
            value: "INPUT_IDS"
        },
        {
            key: "attention_mask"
            value: "ATTENTION_MASK"
        }
        ]
        },
        {
            model_name: "model"
            model_version: -1
        input_map [
            {
                key: "input_ids"
                value: "INPUT_IDS"
            },
            {
                key: "attention_mask"
                value: "ATTENTION_MASK"
            }
        ]
        output_map [
            {
                key: "start_logits"
                value: "START_LOGITS"
            },
            {
                key: "end_logits"
                value: "END_LOGITS"
            }
        ]
        }
    ]
}
version_policy{all {} }
